{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Angel-Castro-RC/Final_NLP/blob/main/F4_1_WordNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C192SOmJS6lw"
      },
      "source": [
        "# CS 195: Natural Language Processing\n",
        "## WordNet\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/f23-CS195NLP/blob/main/F4_1_WordNet.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gPm1vYNYo8A"
      },
      "source": [
        "## References\n",
        "\n",
        "Sample usage for WordNet: https://www.nltk.org/howto/wordnet.html\n",
        "\n",
        "WordNet documentation: https://www.nltk.org/api/nltk.corpus.reader.wordnet.html\n",
        "\n",
        "NLTK Book Chapter 2 (see Section 5): https://www.nltk.org/book/ch02.html\n",
        "\n",
        "Dive into WordNet with NLTK by Norbert Kozlowski: https://medium.com/@don_khozzy/dive-into-wordnet-with-nltk-b313c480e788\n",
        "\n",
        "Getting started with nltk-wordnet in Python: https://www.section.io/engineering-education/getting-started-with-nltk-wordnet-in-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AY7jFoDOYo8A",
        "outputId": "8d2e9efe-439d-4e53-a5a1-1e2f08288514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxOZCaioYo8C"
      },
      "outputs": [],
      "source": [
        "#you shouldn't need to do this in Colab, but I had to do it on my own machine\n",
        "#in order to connect to the nltk service\n",
        "import nltk\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KWfDLrSYo8C",
        "outputId": "90a012d9-d8c1-4b04-a06f-4012fad734e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet') #only need to do this once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emzipofbYo8C"
      },
      "source": [
        "## What is WordNet?\n",
        "\n",
        "**WordNet** is a *lexical database*.\n",
        "\n",
        "So what does that mean? Let's ask WordNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhilBj1hYo8D",
        "outputId": "e44f632e-38b1-45e6-b384-04a1fd5fb403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('lexical.a.01'), Synset('lexical.a.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "wn.synsets(\"lexical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svj-ys3eYo8D"
      },
      "source": [
        "A `synset` is a synonym set - The only synonym set it has of the word *lexical* is the word itself, but it has two different *senses* of the word.\n",
        "\n",
        "`lexical.a.01`\n",
        "* `lexical` is the word\n",
        "* `a` is the part of speech - in this case, adjective\n",
        "* `01` is for the first sense of the word - basically like different entries in a dictionary for the same word\n",
        "\n",
        "<div>\n",
        "    <img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/lexical_definition.png?raw=1\" width=500>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DygnFsQYo8D"
      },
      "source": [
        "We can access each of these synonym sets with `synset` (as opposed to `synsets`) and then call various methods on them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB0YcZ3bYo8E",
        "outputId": "78a24e78-a867-42c8-f656-06af0cd9794b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "of or relating to words\n"
          ]
        }
      ],
      "source": [
        "print( wn.synset('lexical.a.01').definition() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej_xWI2IYo8E",
        "outputId": "12346fe6-8322-4aa3-88f1-22b6fc90f938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "of or relating to dictionaries\n"
          ]
        }
      ],
      "source": [
        "print( wn.synset('lexical.a.02').definition() )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhmqHe-vYo8E"
      },
      "source": [
        "## Let's try another word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3maldvEYo8E",
        "outputId": "5dff48f3-c818-4415-ea7a-b829122d0f88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('bank.n.01'),\n",
              " Synset('depository_financial_institution.n.01'),\n",
              " Synset('bank.n.03'),\n",
              " Synset('bank.n.04'),\n",
              " Synset('bank.n.05'),\n",
              " Synset('bank.n.06'),\n",
              " Synset('bank.n.07'),\n",
              " Synset('savings_bank.n.02'),\n",
              " Synset('bank.n.09'),\n",
              " Synset('bank.n.10'),\n",
              " Synset('bank.v.01'),\n",
              " Synset('bank.v.02'),\n",
              " Synset('bank.v.03'),\n",
              " Synset('bank.v.04'),\n",
              " Synset('bank.v.05'),\n",
              " Synset('deposit.v.02'),\n",
              " Synset('bank.v.07'),\n",
              " Synset('trust.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "wn.synsets(\"bank\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXEu7LYBYo8E"
      },
      "source": [
        "Let's loop through these and print out some information about each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qzHYDutYo8F"
      },
      "outputs": [],
      "source": [
        "senses = wn.synsets(\"bank\")\n",
        "for sense in senses:\n",
        "    print( \"----------------\")\n",
        "    print( sense.name() )\n",
        "    print( sense.pos() )\n",
        "    print( sense.definition() )\n",
        "    print( sense.examples() )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "senses = wn.synsets(\"\")\n",
        "for sense in senses:\n",
        "    print( \"----------------\")\n",
        "    print( sense.name() )\n",
        "    print( sense.pos() )\n",
        "    print( sense.definition() )\n",
        "    print( sense.examples() )"
      ],
      "metadata": {
        "id": "GOMjSKJYbXgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vpb8qSKZcYiM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAJeqex5Yo8F"
      },
      "source": [
        "## Group Exercise\n",
        "\n",
        "Try some additional words. What other parts of speech labels can you find, and what do they mean?\n",
        "\n",
        "You may want to look here too: https://www.nltk.org/api/nltk.corpus.reader.wordnet.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADJ(ADJECTIVE) = 'a'\n",
        "\n",
        "ADJ_SAT (ADJECTIVE SATELLITE) = 's'\n",
        "\n",
        "ADV (ADVERB) = 'r'\n",
        "\n",
        "NOUN = 'n'\n",
        "\n",
        "VERB = 'v'"
      ],
      "metadata": {
        "id": "z0B7BPVtcZ7O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR9kwsN1Yo8F"
      },
      "source": [
        "## Lemmas\n",
        "\n",
        "In linguistics, a **lemma** is the base form of a word.\n",
        "\n",
        "For example: *run*, *ran*, *running*, and *runs* all have the same lemma, **run**\n",
        "\n",
        "Sometimes, you want to **lemmatize** a corpus\n",
        "* change all the words into their base form\n",
        "* can improve NLP tasks like text classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLBUN2Q1Yo8F",
        "outputId": "402d8842-591f-44c1-91a3-e100f57e5480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------\n",
            "run.v.01\n",
            "[Lemma('run.v.01.run')]\n",
            "----------------\n",
            "scat.v.01\n",
            "[Lemma('scat.v.01.scat'), Lemma('scat.v.01.run'), Lemma('scat.v.01.scarper'), Lemma('scat.v.01.turn_tail'), Lemma('scat.v.01.lam'), Lemma('scat.v.01.run_away'), Lemma('scat.v.01.hightail_it'), Lemma('scat.v.01.bunk'), Lemma('scat.v.01.head_for_the_hills'), Lemma('scat.v.01.take_to_the_woods'), Lemma('scat.v.01.escape'), Lemma('scat.v.01.fly_the_coop'), Lemma('scat.v.01.break_away')]\n",
            "----------------\n",
            "run.v.03\n",
            "[Lemma('run.v.03.run'), Lemma('run.v.03.go'), Lemma('run.v.03.pass'), Lemma('run.v.03.lead'), Lemma('run.v.03.extend')]\n",
            "----------------\n",
            "operate.v.01\n",
            "[Lemma('operate.v.01.operate'), Lemma('operate.v.01.run')]\n",
            "----------------\n",
            "run.v.05\n",
            "[Lemma('run.v.05.run'), Lemma('run.v.05.go')]\n",
            "----------------\n",
            "run.v.06\n",
            "[Lemma('run.v.06.run'), Lemma('run.v.06.flow'), Lemma('run.v.06.feed'), Lemma('run.v.06.course')]\n",
            "----------------\n",
            "function.v.01\n",
            "[Lemma('function.v.01.function'), Lemma('function.v.01.work'), Lemma('function.v.01.operate'), Lemma('function.v.01.go'), Lemma('function.v.01.run')]\n",
            "----------------\n",
            "range.v.01\n",
            "[Lemma('range.v.01.range'), Lemma('range.v.01.run')]\n",
            "----------------\n",
            "campaign.v.01\n",
            "[Lemma('campaign.v.01.campaign'), Lemma('campaign.v.01.run')]\n",
            "----------------\n",
            "play.v.18\n",
            "[Lemma('play.v.18.play'), Lemma('play.v.18.run')]\n",
            "----------------\n",
            "run.v.11\n",
            "[Lemma('run.v.11.run')]\n",
            "----------------\n",
            "tend.v.01\n",
            "[Lemma('tend.v.01.tend'), Lemma('tend.v.01.be_given'), Lemma('tend.v.01.lean'), Lemma('tend.v.01.incline'), Lemma('tend.v.01.run')]\n",
            "----------------\n",
            "run.v.13\n",
            "[Lemma('run.v.13.run')]\n",
            "----------------\n",
            "run.v.14\n",
            "[Lemma('run.v.14.run')]\n",
            "----------------\n",
            "run.v.15\n",
            "[Lemma('run.v.15.run')]\n",
            "----------------\n",
            "run.v.16\n",
            "[Lemma('run.v.16.run')]\n",
            "----------------\n",
            "prevail.v.03\n",
            "[Lemma('prevail.v.03.prevail'), Lemma('prevail.v.03.persist'), Lemma('prevail.v.03.die_hard'), Lemma('prevail.v.03.run'), Lemma('prevail.v.03.endure')]\n",
            "----------------\n",
            "run.v.18\n",
            "[Lemma('run.v.18.run')]\n",
            "----------------\n",
            "run.v.19\n",
            "[Lemma('run.v.19.run'), Lemma('run.v.19.execute')]\n",
            "----------------\n",
            "carry.v.15\n",
            "[Lemma('carry.v.15.carry'), Lemma('carry.v.15.run')]\n",
            "----------------\n",
            "run.v.21\n",
            "[Lemma('run.v.21.run')]\n",
            "----------------\n",
            "guide.v.05\n",
            "[Lemma('guide.v.05.guide'), Lemma('guide.v.05.run'), Lemma('guide.v.05.draw'), Lemma('guide.v.05.pass')]\n",
            "----------------\n",
            "run.v.23\n",
            "[Lemma('run.v.23.run'), Lemma('run.v.23.lead')]\n",
            "----------------\n",
            "run.v.24\n",
            "[Lemma('run.v.24.run')]\n",
            "----------------\n",
            "run.v.25\n",
            "[Lemma('run.v.25.run'), Lemma('run.v.25.black_market')]\n",
            "----------------\n",
            "run.v.26\n",
            "[Lemma('run.v.26.run')]\n",
            "----------------\n",
            "run.v.27\n",
            "[Lemma('run.v.27.run'), Lemma('run.v.27.bleed')]\n",
            "----------------\n",
            "run.v.28\n",
            "[Lemma('run.v.28.run')]\n",
            "----------------\n",
            "run.v.29\n",
            "[Lemma('run.v.29.run')]\n",
            "----------------\n",
            "run.v.30\n",
            "[Lemma('run.v.30.run'), Lemma('run.v.30.run_for')]\n",
            "----------------\n",
            "run.v.31\n",
            "[Lemma('run.v.31.run')]\n",
            "----------------\n",
            "run.v.32\n",
            "[Lemma('run.v.32.run'), Lemma('run.v.32.consort')]\n",
            "----------------\n",
            "run.v.33\n",
            "[Lemma('run.v.33.run')]\n",
            "----------------\n",
            "run.v.34\n",
            "[Lemma('run.v.34.run')]\n",
            "----------------\n",
            "ply.v.03\n",
            "[Lemma('ply.v.03.ply'), Lemma('ply.v.03.run')]\n",
            "----------------\n",
            "hunt.v.01\n",
            "[Lemma('hunt.v.01.hunt'), Lemma('hunt.v.01.run'), Lemma('hunt.v.01.hunt_down'), Lemma('hunt.v.01.track_down')]\n",
            "----------------\n",
            "race.v.02\n",
            "[Lemma('race.v.02.race'), Lemma('race.v.02.run')]\n",
            "----------------\n",
            "move.v.13\n",
            "[Lemma('move.v.13.move'), Lemma('move.v.13.go'), Lemma('move.v.13.run')]\n",
            "----------------\n",
            "melt.v.01\n",
            "[Lemma('melt.v.01.melt'), Lemma('melt.v.01.run'), Lemma('melt.v.01.melt_down')]\n",
            "----------------\n",
            "ladder.v.01\n",
            "[Lemma('ladder.v.01.ladder'), Lemma('ladder.v.01.run')]\n",
            "----------------\n",
            "run.v.41\n",
            "[Lemma('run.v.41.run'), Lemma('run.v.41.unravel')]\n"
          ]
        }
      ],
      "source": [
        "run_senses = wn.synsets(\"ran\")\n",
        "\n",
        "# Iterate through the synsets and retrieve lemmas\n",
        "for sense in run_senses:\n",
        "    print( \"----------------\")\n",
        "    print( sense.name() )\n",
        "    lemmas = sense.lemmas()\n",
        "    print( lemmas )\n",
        "    #for lemma in lemmas:\n",
        "    #    print(lemma.name())  # Print the lemma's name"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I0_c83rFc7Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTDmeQ9LYo8F"
      },
      "source": [
        "## Antonyms\n",
        "\n",
        "An **antonym** is a word with an opposite meaning.\n",
        "\n",
        "WordNet organizes antonyms on the lemmas rather than the word senses themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFACzqVUYo8F",
        "outputId": "987d9542-3aee-44d4-b793-14002e445997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('good.a.01.good')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "wn.synset(\"good.a.01\").lemmas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7dRNPzTYo8F"
      },
      "outputs": [],
      "source": [
        "wn.synset(\"good.a.01\").antonyms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_7wZbxmYo8G",
        "outputId": "1d7d5cf5-a238-4ec3-edd8-61dc44a7f2ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('bad.a.01.bad')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "wn.lemma('good.a.01.good').antonyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0SlSJpYo8G"
      },
      "source": [
        "## Hypernyms and Hyponyms\n",
        "\n",
        "**Hypernym:** a more general concept\n",
        "\n",
        "**Hyponynm:** a more specific concept\n",
        "\n",
        "*hyper* - think \"higher\" like hyperactive is higher activity\n",
        "\n",
        "*hypo* - think \"lower\" like when you get hypothermia from being too cold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kowp-ck9Yo8G",
        "outputId": "8980e407-79a8-4b5b-e526-ccc051f871a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01')]\n"
          ]
        }
      ],
      "source": [
        "print( wn.synsets(\"dog\", pos=wn.NOUN) ) # get only the noun synsets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( wn.synsets(\"dog\", pos=wn.VERB) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1U2EHDSd280",
        "outputId": "1755acd0-9879-4626-9517-09787d197c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('chase.v.01')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS7DOpqAYo8G",
        "outputId": "93ea2b44-1479-4ce0-8a91-466dbb94fd99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n"
          ]
        }
      ],
      "source": [
        "dog = wn.synset('dog.n.01')\n",
        "print( dog.definition() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHopfJ3gYo8G",
        "outputId": "1e87497c-b5aa-4075-a344-2c293013e893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dog hypernyms: [Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
            "Dog hyponyms: [Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')]\n",
            "\n",
            "[Synset('carnivore.n.01')]\n",
            "[Synset('placental.n.01')]\n"
          ]
        }
      ],
      "source": [
        "print(\"Dog hypernyms:\", dog.hypernyms())\n",
        "print(\"Dog hyponyms:\", dog.hyponyms())\n",
        "print()\n",
        "print(wn.synset('canine.n.02').hypernyms())\n",
        "print(wn.synset('carnivore.n.01').hypernyms())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdSQghgPYo8G"
      },
      "source": [
        "## Group Exercise\n",
        "\n",
        "Write a loop to print out all the hypernym levels of a given synset - for example\n",
        "\n",
        "dog.n.01\n",
        "\n",
        "canine.n.02\n",
        "\n",
        "carnivore.n.01\n",
        "\n",
        "...\n",
        "\n",
        "You can just choose the first hypernym in the list of hypernyms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synset_id = 'dog.n.01'\n",
        "\n",
        "while True:\n",
        "    # Get the synset object\n",
        "    synset = wn.synset(synset_id)\n",
        "\n",
        "    # Print the current synset\n",
        "    print(synset_id)\n",
        "\n",
        "    # Get the hypernyms of the current synset\n",
        "    hypernyms = synset.hypernyms()\n",
        "\n",
        "    # If there are no hypernyms, break the loop\n",
        "    if not hypernyms:\n",
        "        break\n",
        "\n",
        "    # Choose the first hypernym in the list\n",
        "    synset_id = hypernyms[0].name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKEV6JpjfOUN",
        "outputId": "92a3c6bb-c55b-4b09-a288-131b07807eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog.n.01\n",
            "canine.n.02\n",
            "carnivore.n.01\n",
            "placental.n.01\n",
            "mammal.n.01\n",
            "vertebrate.n.01\n",
            "chordate.n.01\n",
            "animal.n.01\n",
            "organism.n.01\n",
            "living_thing.n.01\n",
            "whole.n.02\n",
            "object.n.01\n",
            "physical_entity.n.01\n",
            "entity.n.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvZ8Q61aYo8G"
      },
      "source": [
        "## Similarity\n",
        "\n",
        "WordNet provides several different kinds of similarity metrics to help you calculate how similar two word senses are.\n",
        "\n",
        "`path_similarity` tells you how close they are based on hypernym/hyponym relationships\n",
        "* 0 means unrelated\n",
        "* 1 means they're the same word sense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMZeaORrYo8G"
      },
      "source": [
        "For example, notice that `dog.n.01` and `wolf.n.01` are both hyponyms of `canine.n.02`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGH3SdTbYo8H",
        "outputId": "930a6748-a1d6-4845-a18a-982f37359a41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('bitch.n.04'),\n",
              " Synset('dog.n.01'),\n",
              " Synset('fox.n.01'),\n",
              " Synset('hyena.n.01'),\n",
              " Synset('jackal.n.01'),\n",
              " Synset('wild_dog.n.01'),\n",
              " Synset('wolf.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "wn.synset(\"canine.n.02\").hyponyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiIWap1VYo8H"
      },
      "source": [
        "Let's calculate some similarities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dog = wn.synset('dog.n.01')\n",
        "wolf = wn.synset('wolf.n.01')\n",
        "canine = wn.synset('canine.n.02')\n",
        "parrot = wn.synset('parrot.n.01')\n",
        "cheese = wn.synset('cheese.n.01')\n",
        "fly_n = wn.synset('fly.n.01')\n",
        "fly_v = wn.synset('fly.v.01')\n",
        "\n",
        "print(\"dog-canine:\", dog.path_similarity(canine))\n",
        "print(\"dog-wolf:\", dog.path_similarity(wolf))\n",
        "print(\"dog-dog:\", dog.path_similarity(dog))\n",
        "print(\"dog-parrot:\", dog.path_similarity(parrot))\n",
        "print(\"dog-cheese:\", dog.path_similarity(cheese))\n",
        "print(\"dog-fly.n:\", dog.path_similarity(fly_n))\n",
        "print(\"dog-fly.v:\", dog.path_similarity(fly_v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ynCTdmEgeNZ",
        "outputId": "2199c7fd-26a2-430d-f000-5cfc3676ca0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog-canine: 0.5\n",
            "dog-wolf: 0.3333333333333333\n",
            "dog-dog: 1.0\n",
            "dog-parrot: 0.14285714285714285\n",
            "dog-cheese: 0.08333333333333333\n",
            "dog-fly.n: 0.125\n",
            "dog-fly.v: 0.08333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EXbaLWjYo8H"
      },
      "source": [
        "## Group Exercise\n",
        "\n",
        "Write a program that takes two words as input and displays the word definitions corresponding to the closest similarity among all of those words' senses."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarities (word1, word2):\n",
        "  synsets1 = wn.synsets(word1)\n",
        "  synsets2 = wn.synsets(word2)\n",
        "\n",
        "  max_similarity = 0\n",
        "  best_pair = None\n",
        "\n",
        "  for synset1 in synsets1:\n",
        "        for synset2 in synsets2:\n",
        "            similarity = synset1.path_similarity(synset2)\n",
        "            if similarity is not None and similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                best_pair = (synset1, synset2)\n",
        "\n",
        "  return best_pair\n",
        "word1 =(\"dog\")\n",
        "word2 = (\"cheese\")\n",
        "best_pair = calculate_similarities(word1, word2)\n",
        "similarity_score =  calculate_similarities(word1, word2)\n",
        "# Display definitions\n",
        "if best_pair:\n",
        "    print(\"\\nDefinitions for the most similar senses:\")\n",
        "    print(f\"{word1}: {best_pair[0].definition()}\")\n",
        "    print(f\"{word2}: {best_pair[1].definition()}\")\n",
        "    print(f\"Similarity Score: {similarity_score}\")\n",
        "else:\n",
        "    print(\"No similar senses found in WordNet.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns4uZNWXgiwr",
        "outputId": "f4a0d54b-c1d0-4362-d087-c16ae5247c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Definitions for the most similar senses:\n",
            "dog: a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
            "cheese: a solid food prepared from the pressed curd of milk\n",
            "Similarity Score: (Synset('frank.n.02'), Synset('cheese.n.01'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3akFkehXYo8H"
      },
      "source": [
        "## Meronyms/Holonyms and Entailment\n",
        "\n",
        "**Holonyms:** denotes membership or parts of something else\n",
        "\n",
        "**Meronym:** denotes thing with members or parts\n",
        "\n",
        "**Entailments:** implies something else"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PQWwzaFYo8H",
        "outputId": "17e8b98f-5e0c-4a6e-c14c-837b35effa61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Synset('canis.n.01'), Synset('pack.n.06')]\n",
            "[Synset('dog.n.01'), Synset('hound.n.01')]\n",
            "[Synset('corn.n.01')]\n",
            "[Synset('corn.n.03'), Synset('corncob.n.01'), Synset('cornstalk.n.01'), Synset('ear.n.05')]\n",
            "[Synset('chew.v.01'), Synset('swallow.v.01')]\n"
          ]
        }
      ],
      "source": [
        "print( wn.synset('dog.n.01').member_holonyms() )\n",
        "print( wn.synset('pack.n.06').member_meronyms() )\n",
        "\n",
        "print( wn.synset(\"corncob.n.01\").part_holonyms() )\n",
        "print( wn.synset(\"corn.n.01\").part_meronyms() )\n",
        "\n",
        "print( wn.synset(\"eat.v.01\").entailments() )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3jIqriUYo8H"
      },
      "source": [
        "## Applied Exploration\n",
        "\n",
        "To get Applied Exploration credit for this workshop, complete all of the group exercises with good programming practices (include comments, well-written functions, etc.). Test your code out on several different examples and include written descriptions of the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0tefiBgYo8I"
      },
      "source": [
        "## Small Project Prototype Idea\n",
        "\n",
        "Use WordNet to make a word game that takes advantages of the relationships present in the database. For example, generate possible words sets for Connections.\n",
        "\n",
        "<div>\n",
        "    <table><tr>\n",
        "        <td><img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/connections1.png?raw=1\" width=500></td>\n",
        "        <td><img src=\"https://github.com/ericmanley/f23-CS195NLP/blob/main/images/connections2.png?raw=1\" width=500></td>\n",
        "    </tr></table>\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}